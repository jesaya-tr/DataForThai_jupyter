{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3750b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e45b9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>รหัส</th>\n",
       "      <th>ประเภทธุรกิจ</th>\n",
       "      <th>จำนวน</th>\n",
       "      <th>จำนวนหน้า</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01111</td>\n",
       "      <td>การปลูกข้าวโพดที่ใช้เมล็ดแก่</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01112</td>\n",
       "      <td>การปลูกธัญพืช (ยกเว้นข้าวและข้าวโพด)</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01113</td>\n",
       "      <td>การปลูกพืชตระกูลถั่ว</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01114</td>\n",
       "      <td>การปลูกถั่วเหลือง</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01115</td>\n",
       "      <td>การปลูกพืชน้ำมัน (ยกเว้นถั่วเหลือง)</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>01461</td>\n",
       "      <td>การเลี้ยงไก่ไข่</td>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>01462</td>\n",
       "      <td>การเลี้ยงไก่เนื้อ</td>\n",
       "      <td>536</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>01463</td>\n",
       "      <td>การเลี้ยงเป็ด</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>01469</td>\n",
       "      <td>การเลี้ยงสัตว์ปีกอื่นๆ ซึ่งมิได้จัดประเภทไว้ใน...</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>01492</td>\n",
       "      <td>การเลี้ยงไหมผีเสื้อและแมลง</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     รหัส                                       ประเภทธุรกิจ  จำนวน  จำนวนหน้า\n",
       "0   01111                       การปลูกข้าวโพดที่ใช้เมล็ดแก่     24          1\n",
       "1   01112               การปลูกธัญพืช (ยกเว้นข้าวและข้าวโพด)     34          1\n",
       "2   01113                               การปลูกพืชตระกูลถั่ว     15          1\n",
       "3   01114                                  การปลูกถั่วเหลือง      3          1\n",
       "4   01115                การปลูกพืชน้ำมัน (ยกเว้นถั่วเหลือง)     10          1\n",
       "..    ...                                                ...    ...        ...\n",
       "57  01461                                    การเลี้ยงไก่ไข่    244          1\n",
       "58  01462                                  การเลี้ยงไก่เนื้อ    536          2\n",
       "59  01463                                      การเลี้ยงเป็ด     22          1\n",
       "60  01469  การเลี้ยงสัตว์ปีกอื่นๆ ซึ่งมิได้จัดประเภทไว้ใน...    173          1\n",
       "61  01492                         การเลี้ยงไหมผีเสื้อและแมลง     19          1\n",
       "\n",
       "[62 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_file = '/Users/bew/Downloads/DataForThai_jupyter/DataForThai_Pandas&SubTopic/SubTopic_dataforthai.csv'\n",
    "topic_table = pd.read_csv(topic_file)\n",
    "\n",
    "\n",
    "topic_table['รหัส'] = topic_table['รหัส'].astype(str)\n",
    "# Function to add '0' to strings of length 4\n",
    "def add_zero(s):\n",
    "    if len(s) == 4:\n",
    "        return '0' + s\n",
    "    else:\n",
    "        return s\n",
    "# Applying the function to the DataFrame\n",
    "topic_table['รหัส'] = topic_table['รหัส'].apply(lambda x: add_zero(x))\n",
    "\n",
    "\n",
    "# topic_table.dtypes\n",
    "topic_table = topic_table[:62]\n",
    "# topic_table = topic_table[608:628]\n",
    "# topic_table = topic_table[topic_table['รหัส']=='46311']\n",
    "# print(topic_table)\n",
    "# max(topic_table['จำนวนหน้า'])\n",
    "topic_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696c3ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3907932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01111 Complete\n",
      "01112 Complete\n",
      "01113 Complete\n",
      "01114 Complete\n",
      "01115 Complete\n",
      "01121 Complete\n",
      "01122 Complete\n",
      "01131 Complete\n",
      "01132 Complete\n",
      "01133 Complete\n",
      "01135 Complete\n",
      "01136 Complete\n",
      "01139 Complete\n",
      "01140 Complete\n",
      "01150 Complete\n",
      "01161 Complete\n",
      "01169 Complete\n",
      "01191 Complete\n",
      "01192 Complete\n",
      "01193 Complete\n",
      "01194 Complete\n",
      "01199 Complete\n",
      "01210 Complete\n",
      "01221 Complete\n",
      "01222 Complete\n",
      "01223 Complete\n",
      "01224 Complete\n",
      "01225 Complete\n",
      "01226 Complete\n",
      "01227 Complete\n",
      "01229 Complete\n",
      "01231 Complete\n",
      "01239 Complete\n",
      "01249 Complete\n",
      "01251 Complete\n",
      "01259 Complete\n",
      "01261 Complete\n",
      "01262 Complete\n",
      "01269 Complete\n",
      "01271 Complete\n",
      "01272 Complete\n",
      "01279 Complete\n",
      "01281 Complete\n",
      "01282 Complete\n",
      "01289 Complete\n",
      "01291 Complete\n",
      "01292 Complete\n",
      "01299 Complete\n",
      "01301 Complete\n",
      "01302 Complete\n",
      "01411 Complete\n",
      "01412 Complete\n",
      "01419 Complete\n",
      "01420 Complete\n",
      "01441 Complete\n",
      "01442 Complete\n",
      "01450 Complete\n",
      "01461 Complete\n",
      "01462 Complete\n",
      "01463 Complete\n",
      "01469 Complete\n",
      "01492 Complete\n"
     ]
    }
   ],
   "source": [
    "# รวมไฟล์\n",
    "\n",
    "# Initialize the result DataFrame\n",
    "result = pd.DataFrame()\n",
    "\n",
    "# Iterate through each row in topic_table\n",
    "for index, row in topic_table.iterrows():\n",
    "    \n",
    "    value1 = row['รหัส']\n",
    "    \n",
    "    for i in range(1,150):\n",
    "        i_str = str(i)  # Convert i to string\n",
    "        file = f'/Users/bew/Downloads/DataForThai_jupyter/DataForThai_Pandas&SubTopic/pf2/{value1}_{i_str}.html'\n",
    "\n",
    "        # Read the HTML file\n",
    "        try:\n",
    "            # Read the HTML file\n",
    "            with open(file, 'r', encoding='utf-8') as file:\n",
    "                html_content = file.read()\n",
    "        except FileNotFoundError:\n",
    "#             check file 1 ว่ามี 400 rows ไหม เผื่อพลาดข้อมูลหน้า 2+\n",
    "            if i == 2:\n",
    "                check_file_400 = f'/Users/bew/Downloads/DataForThai_jupyter/DataForThai_Pandas&SubTopic/pf2/{value1}_1.html'\n",
    "                check_df_file_1 = pd.read_html(check_file_400)\n",
    "                check_df_file_1 = check_df_file_1[1]\n",
    "                if len(check_df_file_1) == 400:\n",
    "                    print(f\"{value1} have full 1 page (check for maybe have more pages)\")\n",
    "            # If the file is not found, break the loop\n",
    "            break\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "        # Find the table (modify as needed to target the correct table)\n",
    "        table = soup.find('table', {'class': 'datatable'})\n",
    "\n",
    "        # Initialize an empty list to store the rows\n",
    "        data = []\n",
    "\n",
    "        # Iterate over each row in the table\n",
    "        for row in table.find_all('tr', class_='click-able-row'):\n",
    "            # Extract the text of each cell\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "\n",
    "            # Extract the onclick attribute\n",
    "            onclick = row.get('onclick')\n",
    "            if onclick:\n",
    "                # Extract the desired values from the onclick string\n",
    "                parts = onclick.split(\"'\")\n",
    "                if len(parts) > 1:\n",
    "                    company_id = parts[1]\n",
    "                    company_name = parts[3]\n",
    "                    row_data.append(company_id)\n",
    "                    row_data.append(company_name)\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        columns = ['Order', 'Name', 'Hidden1', 'Capital', 'Hidden2', 'Province', 'District', 'Company ID', 'Company Name']\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        \n",
    "        df['Capital'] = df['Capital'].str.replace(',', '')\n",
    "        df['Capital'] = pd.to_numeric(df['Capital'])\n",
    "        df = df[(df['Capital'] >= 30000000)]\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        df = df.drop(columns=['Order', 'Name', 'Hidden1', 'Capital', 'Hidden2', 'Province', 'District', 'Company Name'])\n",
    "\n",
    "        # Concatenate df and result DataFrames\n",
    "        result = pd.concat([result, df], axis=0, ignore_index=True)\n",
    "        \n",
    "        \n",
    "#     # Specify the file name and file path\n",
    "#     file_name = value1+'.csv'\n",
    "#     file_path = '/Users/bew/Downloads/WebScrapperFor_DataForThai/DataForThaiCompanyIdsByCategories/'\n",
    "\n",
    "#     # Combine the file path and file name\n",
    "#     full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "#     result.to_csv(full_path, sep=',', index=False, header=True, encoding='utf-8')\n",
    "    print(f\"{value1} Complete\")\n",
    "#     df_null = []\n",
    "#     result = pd.DataFrame(df_null, columns=columns)\n",
    "#     result = result.drop(columns=['Order', 'Name', 'Hidden1', 'Capital', 'Hidden2', 'Province', 'District', 'Company Name'])\n",
    "\n",
    "    # Reset the index of the final result DataFrame\n",
    "#     result = result.reset_index(drop=True)\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e54c80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0505555004367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0515558000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0105526007273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0105536067431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0105533070679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>0255560002362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0725544000555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0305569005230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0305562006712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0605551001438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Company ID\n",
       "0    0505555004367\n",
       "1    0515558000759\n",
       "2    0105526007273\n",
       "3    0105536067431\n",
       "4    0105533070679\n",
       "..             ...\n",
       "552  0255560002362\n",
       "553  0725544000555\n",
       "554  0305569005230\n",
       "555  0305562006712\n",
       "556  0605551001438\n",
       "\n",
       "[557 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.reset_index(drop=True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbbcc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)                                                     # ข้อมูลบริษัททั้งหมด = 44,318 (แต่ยังไม่กรองการดำเนินธุรกิจ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec712432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # แยกไฟล์ตามหัวข้อ\n",
    "\n",
    "# # Initialize the result DataFrame\n",
    "# result = pd.DataFrame()\n",
    "\n",
    "# # Iterate through each row in topic_table\n",
    "# for index, row in topic_table.iterrows():\n",
    "    \n",
    "#     value1 = row['รหัส']\n",
    "    \n",
    "#     for i in range(1,150):\n",
    "#         i_str = str(i)  # Convert i to string\n",
    "#         file = f'/Users/bew/Downloads/DataForThai_Pandas&SubTopic/pf2/{value1}_{i_str}.html'\n",
    "\n",
    "#         # Read the HTML file\n",
    "#         try:\n",
    "#             # Read the HTML file\n",
    "#             with open(file, 'r', encoding='utf-8') as file:\n",
    "#                 html_content = file.read()\n",
    "#         except FileNotFoundError:\n",
    "# #             check file 1 ว่ามี 400 rows ไหม เผื่อพลาดข้อมูลหน้า 2+\n",
    "#             if i == 2:\n",
    "#                 check_file_400 = f'/Users/bew/Downloads/DataForThai_Pandas&SubTopic/pf2/{value1}_1.html'\n",
    "#                 check_df_file_1 = pd.read_html(check_file_400)\n",
    "#                 check_df_file_1 = check_df_file_1[1]\n",
    "#                 if len(check_df_file_1) == 400:\n",
    "#                     print(f\"{value1} have full 1 page (check for maybe have more pages)\")\n",
    "#             # If the file is not found, break the loop\n",
    "#             break\n",
    "\n",
    "#         # Parse the HTML content\n",
    "#         soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "#         # Find the table (modify as needed to target the correct table)\n",
    "#         table = soup.find('table', {'class': 'datatable'})\n",
    "\n",
    "#         # Initialize an empty list to store the rows\n",
    "#         data = []\n",
    "\n",
    "#         # Iterate over each row in the table\n",
    "#         for row in table.find_all('tr', class_='click-able-row'):\n",
    "#             # Extract the text of each cell\n",
    "#             cells = row.find_all('td')\n",
    "#             row_data = [cell.text.strip() for cell in cells]\n",
    "\n",
    "#             # Extract the onclick attribute\n",
    "#             onclick = row.get('onclick')\n",
    "#             if onclick:\n",
    "#                 # Extract the desired values from the onclick string\n",
    "#                 parts = onclick.split(\"'\")\n",
    "#                 if len(parts) > 1:\n",
    "#                     company_id = parts[1]\n",
    "#                     company_name = parts[3]\n",
    "#                     row_data.append(company_id)\n",
    "#                     row_data.append(company_name)\n",
    "\n",
    "#             data.append(row_data)\n",
    "\n",
    "#         # Convert to DataFrame\n",
    "#         columns = ['Order', 'Name', 'Hidden1', 'Capital', 'Hidden2', 'Province', 'District', 'Company ID', 'Company Name']\n",
    "#         df = pd.DataFrame(data, columns=columns)\n",
    "        \n",
    "#         df['Capital'] = df['Capital'].str.replace(',', '')\n",
    "#         df['Capital'] = pd.to_numeric(df['Capital'])\n",
    "#         df = df[(df['Capital'] >= 30000000)]\n",
    "#         df = df.reset_index(drop=True)\n",
    "        \n",
    "#         df = df.drop(columns=['Order', 'Name', 'Hidden1', 'Capital', 'Hidden2', 'Province', 'District', 'Company Name'])\n",
    "\n",
    "#         # Concatenate df and result DataFrames\n",
    "#         result = pd.concat([result, df], axis=0, ignore_index=True)\n",
    "        \n",
    "        \n",
    "#     # Specify the file name and file path\n",
    "#     file_name = value1+'.csv'\n",
    "#     file_path = '/Users/bew/Downloads/WebScrapperFor_DataForThai/DataForThaiCompanyIdsByCategories/'\n",
    "\n",
    "#     # Combine the file path and file name\n",
    "#     full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "#     result.to_csv(full_path, sep=',', index=False, header=True, encoding='utf-8')\n",
    "#     print(f\"{value1} Complete\")\n",
    "#     df_null = []\n",
    "#     result = pd.DataFrame(df_null, columns=columns)\n",
    "#     result = result.drop(columns=['Order', 'Name', 'Hidden1', 'Capital', 'Hidden2', 'Province', 'District', 'Company Name'])\n",
    "\n",
    "#     # Reset the index of the final result DataFrame\n",
    "#     result = result.reset_index(drop=True)\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93bad2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1071fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value1 = '01111'\n",
    "\n",
    "# file = '/Users/bew/Downloads/GetData_DataForThai/passthrough/'+value1+'_1.html'\n",
    "# # Read the HTML file\n",
    "# with open(file, 'r', encoding='utf-8') as file:\n",
    "#     html_content = file.read()\n",
    "\n",
    "# # Parse the HTML content\n",
    "# soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "# # Find the table (modify as needed to target the correct table)\n",
    "# table = soup.find('table', {'class': 'datatable'})\n",
    "\n",
    "# # # Convert the table to a pandas DataFrame\n",
    "# # df = pd.read_html(str(table))[0]\n",
    "\n",
    "# # Initialize an empty list to store the rows\n",
    "# data = []\n",
    "\n",
    "# # Iterate over each row in the table\n",
    "# for row in table.find_all('tr', class_='click-able-row'):\n",
    "#     # Extract the text of each cell\n",
    "#     cells = row.find_all('td')\n",
    "#     row_data = [cell.text.strip() for cell in cells]\n",
    "\n",
    "#     # Extract the onclick attribute\n",
    "#     onclick = row.get('onclick')\n",
    "#     if onclick:\n",
    "#         # Extract the desired values from the onclick string\n",
    "#         parts = onclick.split(\"'\")\n",
    "#         if len(parts) > 1:\n",
    "#             company_id = parts[1]\n",
    "#             company_name = parts[3]\n",
    "#             row_data.append(company_id)\n",
    "#             row_data.append(company_name)\n",
    "\n",
    "#     data.append(row_data)\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# columns = ['Order', 'Name', 'Hidden1', 'Capital', 'Hidden2', 'Province', 'District', 'Company ID', 'Company Name']\n",
    "# df = pd.DataFrame(data, columns=columns)\n",
    "# # df = df.drop(columns=['Order', 'Name', 'Hidden1', 'Hidden2', 'Province', 'District'])\n",
    "# df = df.drop(columns=['Order', 'Name', 'Hidden1', 'Hidden2', 'Province', 'District'])\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e65c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value2 = '01112'\n",
    "\n",
    "# file2 = '/Users/bew/Downloads/GetData_DataForThai/passthrough/'+value2+'_1.html'\n",
    "# # Read the HTML file\n",
    "# with open(file2, 'r', encoding='utf-8') as file:\n",
    "#     html_content = file.read()\n",
    "\n",
    "# # Parse the HTML content\n",
    "# soup = BeautifulSoup(html_content, 'lxml')\n",
    "\n",
    "# # Find the table (modify as needed to target the correct table)\n",
    "# table = soup.find('table', {'class': 'datatable'})\n",
    "\n",
    "# # # Convert the table to a pandas DataFrame\n",
    "# # df = pd.read_html(str(table))[0]\n",
    "\n",
    "# # Initialize an empty list to store the rows\n",
    "# data = []\n",
    "\n",
    "# # Iterate over each row in the table\n",
    "# for row in table.find_all('tr', class_='click-able-row'):\n",
    "#     # Extract the text of each cell\n",
    "#     cells = row.find_all('td')\n",
    "#     row_data = [cell.text.strip() for cell in cells]\n",
    "\n",
    "#     # Extract the onclick attribute\n",
    "#     onclick = row.get('onclick')\n",
    "#     if onclick:\n",
    "#         # Extract the desired values from the onclick string\n",
    "#         parts = onclick.split(\"'\")\n",
    "#         if len(parts) > 1:\n",
    "#             company_id = parts[1]\n",
    "#             company_name = parts[3]\n",
    "#             row_data.append(company_id)\n",
    "#             row_data.append(company_name)\n",
    "\n",
    "#     data.append(row_data)\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# columns = ['Order', 'Name', 'Hidden1', 'Capital', 'Hidden2', 'Province', 'District', 'Company ID', 'Company Name']\n",
    "# df2 = pd.DataFrame(data, columns=columns)\n",
    "# # df = df.drop(columns=['Order', 'Name', 'Hidden1', 'Hidden2', 'Province', 'District'])\n",
    "# df2 = df2.drop(columns=['Order', 'Name', 'Hidden1', 'Hidden2', 'Province', 'District'])\n",
    "\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd555e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c35d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '/Users/bew/Downloads/GetData_DataForThai/passthrough/01111_1.html'\n",
    "# df = pd.read_html(file)\n",
    "# df = df[1]\n",
    "# # df.dtypes\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "975a884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = '1'\n",
    "# file = '/Users/bew/Downloads/GetData_DataForThai/passthrough/01112_1.html'\n",
    "# df = pd.read_html(file)\n",
    "# df = df[1]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39a3982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for index, row in df.iterrows():\n",
    "# file_m = '/Users/bew/Downloads/GetData_DataForThai/passthrough/01112_1.html'\n",
    "# df_m = pd.read_html(file_m)\n",
    "# df_m = df_m[1]\n",
    "# df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30ff8315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.concat([df, df_m], axis=0)\n",
    "# # print(result)\n",
    "\n",
    "# result = result.reset_index(drop=True)\n",
    "# result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
